{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3DeRkfboVUtrlZWPnIbkH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dashx7/ESP32-img-recognition/blob/main/ESP32_img_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Board: ESP32 Image Recognition for Terrain Classification**\n",
        "\n",
        "## **1. Import Dataset**\n",
        "- **Details**: Gather and organize image data.\n",
        "- **Tasks**:\n",
        "  - Source image data relevant to different terrain types.\n",
        "  - Convert images into a format compatible with PyTorch (e.g., tensors).\n",
        "  - Pull data as CSVs?\n",
        "  - Determine and standardize image resolution (e.g., resize if needed).\n",
        "\n",
        "## **2. Data Preprocessing**\n",
        "- **Tasks**:\n",
        "  - Normalize image pixel values.\n",
        "  - Apply data augmentation techniques (e.g., rotations, flips) to increase dataset variability.\n",
        "  -- torchvision.transforms can be used in a DataLoader pipeline to apply augmentations such as random rotations, flips, or color jittering directly when loading the batch so maybe just do it dynamically\n",
        "  - Split data randomly into training, validation, and test sets.\n",
        "\n",
        "## **3. Model Architecture**\n",
        "- **Framework**: PyTorch\n",
        "- **Tasks**:\n",
        "  - Define the architecture of the neural network (e.g., CNN for image recognition).\n",
        "  - Choose the number of layers and nodes based on complexity.\n",
        "  - Integrate dropout layers if necessary to prevent overfitting.\n",
        "\n",
        "## **4. Loss Function**\n",
        "- **Details**:\n",
        "  - Select a suitable loss function, such as `CrossEntropyLoss` for classification tasks.\n",
        "- **Tasks**:\n",
        "  - Research and set up the initial loss function.\n",
        "  - Fine-tune or consider alternatives if performance needs improvement.\n",
        "\n",
        "## **5. Training**\n",
        "- **Framework**: PyTorch\n",
        "- **Optimizer**: Adam optimizer\n",
        "- **Tasks**:\n",
        "  - Implement training loop with forward pass, backward pass, and parameter updates.\n",
        "  - Set up early stopping criteria or callbacks for monitoring validation loss.\n",
        "  - Log performance metrics (e.g., loss and accuracy at each epoch).\n",
        "\n",
        "## **6. Evaluation and Testing**\n",
        "- **Tasks**:\n",
        "  - Evaluate model on the test dataset.\n",
        "  - Plot model performance\n",
        "  - Create confusion matrix and other relevant metrics (e.g., precision, recall).\n",
        "  - Fine-tune the model as needed based on results.\n",
        "\n",
        "## **7. Deployment**\n",
        "- **Tasks**:\n",
        "  - Test the model with real-time ESP32 input.\n",
        "  - Optimize the model for deployment, considering the constraints of the ESP32. Such as how often we try to judge an image\n",
        "  - Convert the PyTorch model to a lightweight format compatible with the device (e.g., use ONNX or TensorFlow Lite). IDK about this tbh?\n",
        "\n",
        "## **8. Documentation**\n",
        "- **Tasks**:\n",
        "  - Write clear documentation for data collection, training process, and model architecture.\n",
        "\n"
      ],
      "metadata": {
        "id": "uLXVYjOf3bJR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Import Dataset**\n",
        "\n"
      ],
      "metadata": {
        "id": "OBHLCbW-8ve2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "unUIy1P89Dvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Data Preprocessing**\n"
      ],
      "metadata": {
        "id": "8DwADhvf84zM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "diIgPYno85Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Training**\n"
      ],
      "metadata": {
        "id": "dC0NpPAK85Ki"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIyvD-d43W9N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Evaluation and Testing**\n"
      ],
      "metadata": {
        "id": "DsGjDF7E9DhL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yNx1ruAW84Z5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}